{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0999268b",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6dd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "def load_model(model_name: str):\n",
    "    model = api.load(model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc8b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def initialize_data(file_name: str):\n",
    "    # Load csv file\n",
    "    rows = []\n",
    "    with open(f'in/{file_name}', 'r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "\n",
    "        _ = next(csv_reader)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "\n",
    "        print(f\"{csv_reader.line_num - 1} rows appended\")\n",
    "    return rows\n",
    "    \n",
    "\n",
    "def output_model_performance(model_name: str, model, rows):\n",
    "    with open(f'out/{model_name}-details.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # labels are guess, correct or wrong\n",
    "        header = ['question', 'answer', 'guess', 'label']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for row in rows:\n",
    "            pairs = []\n",
    "            similarities = []\n",
    "\n",
    "            # create word-possible_synonym pairs\n",
    "            for token in row[2:]:\n",
    "                pairs.append((row[0], token))\n",
    "\n",
    "            for w1, w2 in pairs:\n",
    "                try:\n",
    "                    temp = model.similarity(w1,w2)\n",
    "                    similarities.append((w2,temp))\n",
    "                except KeyError:\n",
    "                    similarities.append((w2,-1))\n",
    "\n",
    "\n",
    "\n",
    "            # result\n",
    "            guess = max(similarities, key=lambda x: float(x[1]))\n",
    "\n",
    "            # labels\n",
    "            label = 'wrong'\n",
    "            if guess[1] == -1:\n",
    "                label = 'guess'\n",
    "            elif row[1] == guess[0]:\n",
    "                label = 'correct'\n",
    "\n",
    "            data = [row[0], row[1], guess[0], label]\n",
    "            writer.writerow(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7eecf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the details\n",
    "def analyze_model_results(model_name: str, model, append=False):\n",
    "    rows = []\n",
    "    with open(f'out/{model_name}-details.csv', 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "\n",
    "        _ = next(csv_reader)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "\n",
    "    # writing the analysis\n",
    "    write_mode = 'a' if append else 'w'\n",
    "    with open ('out/analysis.csv', write_mode) as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        header = ['model', 'size_of_vocab', 'C', 'V', 'accuracy']\n",
    "        if not append:\n",
    "            writer.writerow(header)\n",
    "            \n",
    "        C = 0\n",
    "        G = 0\n",
    "        V = 0\n",
    "        size_of_vocab = len(model)\n",
    "        for row in rows:\n",
    "            if row[-1] == 'correct':\n",
    "                C += 1\n",
    "            elif row[-1] == 'guess':\n",
    "                G += 1\n",
    "        V = len(rows) - G\n",
    "        acc = C/V\n",
    "        data = [model_name, size_of_vocab, C, V, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed98bd",
   "metadata": {},
   "source": [
    "# Load Models (ONLY RUN ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adcfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec-google-news-300\n",
    "wv = load_model('word2vec-google-news-300')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa64b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# glove-twitter-200\n",
    "tw200 = load_model('glove-twitter-200')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286f4e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# glove-twitter-100\n",
    "tw100 = load_model('glove-twitter-100')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67088d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 15.1% 38.1/252.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 26.1% 65.9/252.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.7% 95.0/252.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.4% 124.6/252.1MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 252.1/252.1MB downloaded\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# glove-wiki-gigaword-200\n",
    "wi200 = load_model('glove-wiki-gigaword-200')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a5eb010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# glove-wiki-gigaword-100\n",
    "wi100 = load_model('glove-wiki-gigaword-100')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3d258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 rows appended\n"
     ]
    }
   ],
   "source": [
    "data_file = 'synonyms.csv'\n",
    "\n",
    "# initialize\n",
    "rows = initialize_data(data_file)\n",
    "\n",
    "# output model performance\n",
    "output_model_performance('word2vec-google-news-300', wv, rows) # TASK 1\n",
    "# TASK 2\n",
    "output_model_performance('glove-twitter-200', tw200, rows)\n",
    "output_model_performance('glove-twitter-100', tw100, rows)\n",
    "output_model_performance('glove-wiki-gigaword-200', wi200, rows)\n",
    "output_model_performance('glove-wiki-gigaword-100', wi100, rows)\n",
    "\n",
    "# analyze\n",
    "analyze_model_results('word2vec-google-news-300', wv) # TASK 1\n",
    "# TASK 2\n",
    "analyze_model_results('glove-twitter-200', tw200, True)\n",
    "analyze_model_results('glove-twitter-100', tw100, True)\n",
    "analyze_model_results('glove-wiki-gigaword-200', wi200, True)\n",
    "analyze_model_results('glove-wiki-gigaword-100', wi100, True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
